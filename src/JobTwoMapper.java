import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

/**
 * Reads the intermediate file generated by job one splits it across the word
 * separator that we used and generates key as the number of anagrams and
 * string as space seperated words(as needed in the final output)
 */
public class JobTwoMapper extends Mapper<Object, Text, IntWritable, Text> {

    private static final String SPACE = " ";

    @Override
    protected void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        String[] words = value.toString().split(Constants.WORD_SEPARATOR);
        StringBuilder sb = new StringBuilder();
        int counter = 0;
        for (String word : words) {
            sb.append(word);
            if (counter != words.length - 1) {
                sb.append(SPACE);
            }
            counter++;
        }
        context.write(new IntWritable(counter), new Text(sb.toString()));
    }

}
